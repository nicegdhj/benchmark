# æ¨¡å‹é…ç½®è¯´æ˜
AISBench Benchmark æ”¯æŒä¸¤ç±»æ¨¡å‹åç«¯ï¼š
- [æœåŠ¡åŒ–æ¨ç†åç«¯](#æœåŠ¡åŒ–æ¨ç†åç«¯)
- [æœ¬åœ°æ¨¡å‹åç«¯](#æœ¬åœ°æ¨¡å‹åç«¯)

> âš ï¸ æ³¨æ„ï¼š ä¸èƒ½åŒæ—¶æŒ‡å®šä¸¤ç§åç«¯ã€‚
## æœåŠ¡åŒ–æ¨ç†åç«¯
AISBench Benchmark æ”¯æŒå¤šç§æœåŠ¡åŒ–æ¨ç†åç«¯ï¼ŒåŒ…æ‹¬ vLLMã€SGLangã€Tritonã€MindIEã€TGI ç­‰ã€‚è¿™äº›åç«¯é€šè¿‡æš´éœ²çš„ HTTP API æ¥å£æ¥æ”¶æ¨ç†è¯·æ±‚å¹¶è¿”å›ç»“æœã€‚ï¼ˆç›®å‰ä¸æ”¯æŒ HTTPS æ¥å£ï¼‰

ä»¥åœ¨ GPU ä¸Šéƒ¨ç½²çš„ vLLM æ¨ç†æœåŠ¡ä¸ºä¾‹ï¼Œæ‚¨å¯ä»¥å‚è€ƒ [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/en/stable/getting_started/quickstart.html) å¯åŠ¨æœåŠ¡ã€‚

ä¸åŒæœåŠ¡åŒ–åç«¯å¯¹åº”çš„æ¨¡å‹é…ç½®å¦‚ä¸‹ï¼š
| æ¨¡å‹é…ç½®åç§°| ç®€ä»‹| ä½¿ç”¨å‰æ| æ”¯æŒçš„æµ‹è¯„æ¨¡å¼ | æ¥å£ç±»å‹ | æ”¯æŒçš„æ•°æ®é›† Prompt æ ¼å¼ | é…ç½®æ–‡ä»¶è·¯å¾„|
| ---------- | ---------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| `vllm_api_general` | é€šè¿‡ vLLM å…¼å®¹ OpenAI çš„ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v1/completions`| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/completions` å­æœåŠ¡| ç”Ÿæˆå¼æµ‹è¯„ã€PPLæ¨¡å¼æµ‹è¯„ | æ–‡æœ¬æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼| [vllm_api_general.py](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/vllm_api/vllm_api_general.py)|
| `vllm_api_general_stream`| æµå¼è®¿é—® vLLM æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v1/completions`| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/completions` å­æœåŠ¡ | ç”Ÿæˆå¼æµ‹è¯„| æµå¼æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼| [vllm_api_general_stream.py](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/vllm_api/vllm_api_general_stream.py) |
| `vllm_api_general_chat`  | é€šè¿‡ vLLM å…¼å®¹ OpenAI çš„ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v1/chat/completions` | åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/chat/completions` å­æœåŠ¡ | ç”Ÿæˆå¼æµ‹è¯„ã€PPLæ¨¡å¼æµ‹è¯„ | æ–‡æœ¬æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¯¹è¯æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼ | [vllm_api_general_chat.py](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/vllm_api/vllm_api_general_chat.py)  |
| `vllm_api_stream_chat`| æµå¼è®¿é—® vLLM æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v1/chat/completions`| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/chat/completions` å­æœåŠ¡ | ç”Ÿæˆå¼æµ‹è¯„ | æµå¼æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¯¹è¯æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼ | [vllm_api_stream_chat.py](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/vllm_api/vllm_api_stream_chat.py) |
| `vllm_api_stream_chat_multiturn`| å¤šè½®å¯¹è¯åœºæ™¯çš„æµå¼è®¿é—® vLLM æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v1/chat/completions`| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/chat/completions` å­æœåŠ¡ | ç”Ÿæˆå¼æµ‹è¯„ | æµå¼æ¥å£ | å¯¹è¯æ ¼å¼ | [vllm_api_stream_chat_multiturn.py](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/vllm_api/vllm_api_stream_chat_multiturn.py) |
| `vllm_api_function_call_chat`| function callç²¾åº¦æµ‹è¯„åœºæ™¯è®¿é—® vLLM æ¨ç†æœåŠ¡çš„API ï¼Œæ¥å£ä¸º `v1/chat/completions`ï¼ˆåªé€‚ç”¨äº[BFCL](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/datasets/BFCL/README.md)æµ‹è¯„åœºæ™¯| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/chat/completions` å­æœåŠ¡ | ç”Ÿæˆå¼æµ‹è¯„ | æ–‡æœ¬æ¥å£ | å¯¹è¯æ ¼å¼ | [vllm_api_function_call_chat.py](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/vllm_api/vllm_api_function_call_chat.py) |
| `vllm_api_old`  | é€šè¿‡ vLLM å…¼å®¹ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `generate`| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `generate` å­æœåŠ¡ | ç”Ÿæˆå¼æµ‹è¯„ | æ–‡æœ¬æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼| [vllm_api_old.py](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/vllm_api/vllm_api_old.py)|
| `mindie_stream_api_general` | é€šè¿‡ MindIE æµå¼ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `infer`| åŸºäº MindIE ç‰ˆæœ¬æ”¯æŒ `infer` å­æœåŠ¡ | ç”Ÿæˆå¼æµ‹è¯„ | æµå¼æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼| [mindie_stream_api_general.py](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/mindie_api/mindie_stream_api_general.py) |
| `triton_api_general`  | é€šè¿‡ Triton API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v2/models/{model name}/generate`  | å¯åŠ¨æ”¯æŒ Triton API çš„æ¨ç†æœåŠ¡ | ç”Ÿæˆå¼æµ‹è¯„ | æ–‡æœ¬æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼| [triton_api_general.py](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/triton_api/triton_api_general.py) |
| `triton_stream_api_general` | é€šè¿‡ Triton æµå¼ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v2/models/{model name}/generate_stream` | å¯åŠ¨æ”¯æŒ Triton API çš„æ¨ç†æœåŠ¡ | ç”Ÿæˆå¼æµ‹è¯„ | æµå¼æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼ | [triton_stream_api_general.py](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/triton_api/triton_stream_api_general.py) |
| `tgi_api_general`  | é€šè¿‡ TGI API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `generate`| å¯åŠ¨æ”¯æŒ TGI API çš„æ¨ç†æœåŠ¡ | ç”Ÿæˆå¼æµ‹è¯„ | æ–‡æœ¬æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼| [tgi_api_general](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/tgi_api/tgi_api_general.py)|
| `tgi_stream_api_general` | é€šè¿‡ TGI æµå¼ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `generate_stream`| å¯åŠ¨æ”¯æŒ TGI API çš„æ¨ç†æœåŠ¡ | ç”Ÿæˆå¼æµ‹è¯„ | æµå¼æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼| [tgi_stream_api_general](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/tgi_api/tgi_stream_api_general.py) |

### æœåŠ¡åŒ–æ¨ç†åç«¯é…ç½®å‚æ•°è¯´æ˜
æœåŠ¡åŒ–æ¨ç†åç«¯é…ç½®æ–‡ä»¶é‡‡ç”¨Pythonè¯­æ³•æ ¼å¼é…ç½®ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š
```python
from ais_bench.benchmark.models import VLLMCustomAPI

models = [
    dict(
        attr="service",
        type=VLLMCustomAPI,
        abbr='vllm-api-general',
        path="",                    # æŒ‡å®šæ¨¡å‹åºåˆ—åŒ–è¯è¡¨æ–‡ä»¶ç»å¯¹è·¯å¾„ï¼ˆç²¾åº¦æµ‹è¯•åœºæ™¯ä¸€èˆ¬ä¸éœ€è¦é…ç½®ï¼‰
        model="",        # æŒ‡å®šæœåŠ¡ç«¯å·²åŠ è½½æ¨¡å‹åç§°ï¼Œä¾æ®å®é™…VLLMæ¨ç†æœåŠ¡æ‹‰å–çš„æ¨¡å‹åç§°é…ç½®ï¼ˆé…ç½®æˆç©ºå­—ç¬¦ä¸²ä¼šè‡ªåŠ¨è·å–ï¼‰
        stream=False,    # æ˜¯å¦ä¸ºæµå¼æ¥å£
        request_rate = 0,           # è¯·æ±‚å‘é€é¢‘ç‡ï¼Œæ¯1/request_rateç§’å‘é€1ä¸ªè¯·æ±‚ç»™æœåŠ¡ç«¯ï¼Œå°äº0.1åˆ™ä¸€æ¬¡æ€§å‘é€æ‰€æœ‰è¯·æ±‚
        retry = 2,                  # æ¯ä¸ªè¯·æ±‚æœ€å¤§é‡è¯•æ¬¡æ•°
        api_key="",               # è‡ªå®šä¹‰API keyï¼Œé»˜è®¤æ˜¯ç©ºå­—ç¬¦ä¸²
        host_ip = "localhost",      # æŒ‡å®šæ¨ç†æœåŠ¡çš„IP
        host_port = 8080,           # æŒ‡å®šæ¨ç†æœåŠ¡çš„ç«¯å£
        url="",                     # è‡ªå®šä¹‰è®¿é—®æ¨ç†æœåŠ¡çš„URLè·¯å¾„(å½“base urlä¸æ˜¯http://host_ip:host_portçš„ç»„åˆæ—¶éœ€è¦é…ç½®)
        max_out_len = 512,          # æ¨ç†æœåŠ¡è¾“å‡ºçš„tokençš„æœ€å¤§æ•°é‡
        batch_size=1,               # è¯·æ±‚å‘é€çš„æœ€å¤§å¹¶å‘æ•°
        trust_remote_code=False,    # tokenizeræ˜¯å¦ä¿¡ä»»è¿œç¨‹ä»£ç ï¼Œé»˜è®¤False;
        generation_kwargs = dict(   # æ¨¡å‹æ¨ç†å‚æ•°ï¼Œå‚è€ƒVLLMæ–‡æ¡£é…ç½®ï¼ŒAISBenchè¯„æµ‹å·¥å…·ä¸åšå¤„ç†ï¼Œåœ¨å‘é€çš„è¯·æ±‚ä¸­é™„å¸¦
            temperature = 0.01,
            ignore_eos=False,
        )
    )
]

```

æœåŠ¡åŒ–æ¨ç†åç«¯å¯é…ç½®å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š
| å‚æ•°åç§° | å‚æ•°ç±»å‹ | é…ç½®è¯´æ˜ |
|----------|-----------|-------------|
| `attr` | String | æ¨ç†åç«¯ç±»å‹æ ‡è¯†ï¼Œå›ºå®šä¸º `service`ï¼ˆæœåŠ¡åŒ–æ¨ç†ï¼‰æˆ– `local`ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰ï¼Œä¸å¯é…ç½® |
| `type` | Python Class | API ç±»å‹ç±»åï¼Œç”±ç³»ç»Ÿè‡ªåŠ¨å…³è”ï¼Œç”¨æˆ·æ— éœ€æ‰‹åŠ¨é…ç½®ï¼Œå‚è€ƒ [æœåŠ¡åŒ–æ¨ç†åç«¯](#æœåŠ¡åŒ–æ¨ç†åç«¯) |
| `abbr` | String | æœåŠ¡åŒ–ä»»åŠ¡çš„å”¯ä¸€æ ‡è¯†ï¼Œç”¨äºåŒºåˆ†ä¸åŒä»»åŠ¡ï¼Œè‹±æ–‡å­—ç¬¦ä¸çŸ­æ¨ªçº¿ç»„åˆï¼Œä¾‹å¦‚ï¼š`vllm-api-general-chat` |
| `path` | String | Tokenizer è·¯å¾„ï¼Œé€šå¸¸ä¸æ¨¡å‹è·¯å¾„ç›¸åŒï¼Œä½¿ç”¨ `AutoTokenizer.from_pretrained(path)` åŠ è½½ã€‚æŒ‡å®šå¯è®¿é—®çš„æœ¬åœ°è·¯å¾„ï¼Œä¾‹å¦‚ï¼š`/weight/DeepSeek-R1` |
| `model` | String | æœåŠ¡ç«¯å¯è®¿é—®çš„æ¨¡å‹åç§°ï¼Œå¿…é¡»ä¸æœåŠ¡åŒ–éƒ¨ç½²æ—¶æŒ‡å®šçš„åç§°ä¸€è‡´ |
| `model_name` | String | ä»…é€‚ç”¨äº Triton æœåŠ¡ï¼Œæ‹¼æ¥ä¸º endpoint çš„ URI `/v2/models/{modelname}/{inferã€generateã€generate_stream}`ï¼Œåº”ä¸éƒ¨ç½²æ—¶åç§°ä¸€è‡´ |
| `stream` | Boolean | APIæ¨¡å‹æ¨ç†æ¥å£ç±»å‹ï¼Œé»˜è®¤ä¸ºFalseï¼Œè¡¨ç¤ºéæµå¼æ¥å£ï¼Œå½“ä¸ºTrueæ—¶è¡¨ç¤ºæµå¼æ¥å£ï¼ˆå…·ä½“è¯·å‚è€ƒğŸ”—[æœåŠ¡åŒ–æ¨ç†åç«¯](#æœåŠ¡åŒ–æ¨ç†åç«¯)ï¼‰|
| `request_rate` | Float | è¯·æ±‚å‘é€é€Ÿç‡ï¼ˆå•ä½ï¼šç§’ï¼‰ï¼Œæ¯éš” `1/request_rate` ç§’å‘é€ä¸€ä¸ªè¯·æ±‚ï¼›å‹æµ‹åœºæ™¯ä¸‹è¡¨ç¤ºæ¯ç§’æ–°å¢çš„æœåŠ¡ç«¯è¿æ¥æ•°ï¼›è‹¥å°äº 0.1 è¡¨ç¤ºä¸é™åˆ¶è¯·æ±‚å‘é€é€Ÿç‡ã€‚åˆæ³•èŒƒå›´ï¼š[0, 64000]ã€‚å½“`traffic_cfg`é¡¹é…ç½®å¯ç”¨æ—¶ï¼Œè¯¥é¡¹åŠŸèƒ½å¯èƒ½è¢«è¦†ç›– ï¼ˆå…·ä½“åŸå› è¯·å‚è€ƒ ğŸ”— [è¯·æ±‚é€Ÿç‡(RPS)åˆ†å¸ƒæ§åˆ¶åŠå¯è§†åŒ–è¯´æ˜ä¸­çš„å‚æ•°è§£è¯»ç« èŠ‚](../../advanced_tutorials/rps_distribution.md#å‚æ•°è§£è¯»)ï¼‰|
| `traffic_cfg` | Dict | è¯·æ±‚å‘é€é€Ÿç‡æ³¢åŠ¨æ§åˆ¶å‚æ•°ï¼ˆå…·ä½“ä½¿ç”¨è¯´æ˜è¯·å‚è€ƒ ğŸ”— [è¯·æ±‚é€Ÿç‡(RPS)åˆ†å¸ƒæ§åˆ¶åŠå¯è§†åŒ–è¯´æ˜](../../advanced_tutorials/rps_distribution.md)ï¼‰ï¼Œä¸å¡«å†™æ­¤é¡¹é»˜è®¤ä¸å¯ç”¨è¯¥åŠŸèƒ½ã€‚ |
| `retry` | Int | è¿æ¥æœåŠ¡ç«¯å¤±è´¥åçš„æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚åˆæ³•èŒƒå›´ï¼š[0, 1000] |
| `api_key` | String | è‡ªå®šä¹‰API keyï¼Œé»˜è®¤æ˜¯ç©ºå­—ç¬¦ä¸²ã€‚ä»…æ”¯æŒ `VLLMCustomAPI` å’Œ `VLLMCustomAPIChat` æ¨¡å‹ç±»å‹ã€‚ |
| `host_ip` | String | æœåŠ¡ç«¯ IP åœ°å€ï¼Œæ”¯æŒåˆæ³• IPv4 æˆ– IPv6ï¼Œä¾‹å¦‚ï¼š`127.0.0.1` |
| `host_port` | Int | æœåŠ¡ç«¯ç«¯å£å·ï¼Œåº”ä¸æœåŠ¡åŒ–éƒ¨ç½²æŒ‡å®šçš„ç«¯å£ä¸€è‡´ |
| `url` | String | è‡ªå®šä¹‰è®¿é—®æ¨ç†æœåŠ¡çš„URLè·¯å¾„(å½“base urlä¸æ˜¯http/https://host_ip:host_portçš„ç»„åˆæ—¶éœ€è¦é…ç½®ï¼Œé…ç½®åhost_ipå’Œhost_portå°†è¢«å¿½ç•¥) ï¼Œä¾‹å¦‚å½“`models`çš„`type`ä¸º`VLLMCustomAPI`æ—¶ï¼Œé…ç½®`url`ä¸º`https://xxxxxxx/yyyy/`ï¼Œå®é™…è¯·æ±‚è®¿é—®çš„URLä¸º`https://xxxxxxx/yyyy/v1/completions`|
| `max_out_len` | Int | æ¨ç†å“åº”çš„æœ€å¤§è¾“å‡ºé•¿åº¦ï¼Œå®é™…é•¿åº¦å¯èƒ½å—æœåŠ¡ç«¯é™åˆ¶ã€‚åˆæ³•èŒƒå›´ï¼š(0, 131072] |
| `batch_size` | Int | è¯·æ±‚çš„å¹¶å‘æ‰¹å¤„ç†å¤§å°ã€‚åˆæ³•èŒƒå›´ï¼š(0, 64000] |
| `trust_remote_code` | Boolean | tokenizeræ˜¯å¦ä¿¡ä»»è¿œç¨‹ä»£ç ï¼Œé»˜è®¤False; |
| `generation_kwargs` | Dict | æ¨ç†ç”Ÿæˆå‚æ•°é…ç½®ï¼Œä¾èµ–å…·ä½“çš„æœåŠ¡åŒ–åç«¯å’Œæ¥å£ç±»å‹ã€‚æ³¨æ„ï¼šå½“å‰ä¸æ”¯æŒ `best_of` å’Œ `n` ç­‰å¤šæ¬¡é‡‡æ ·å‚æ•°ï¼Œä½†æ”¯æŒé€šè¿‡`num_return_sequences`å‚æ•°è¿›è¡Œå¤šæ¬¡ç‹¬ç«‹æ¨ç†(å…·ä½“è¯·å‚è€ƒğŸ”—[Text Generation æ–‡æ¡£](https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.num_return_sequences)ä¸­`num_return_sequences`çš„ä½œç”¨) |
| `returns_tool_calls` | Bool | æ§åˆ¶å‡½æ•°è°ƒç”¨ä¿¡æ¯çš„æå–æ–¹å¼ã€‚å½“è®¾ç½®ä¸ºTrueæ—¶ï¼Œç³»ç»Ÿä»APIå“åº”çš„`tool_calls`å­—æ®µä¸­æå–å‡½æ•°è°ƒç”¨ä¿¡æ¯ï¼›å½“è®¾ç½®ä¸ºFalseæ—¶ï¼Œç³»ç»Ÿä»`content`å­—æ®µä¸­è§£æå‡½æ•°è°ƒç”¨ä¿¡æ¯ |
| `pred_postprocessor` | Dict | æ¨¡å‹è¾“å‡ºç»“æœçš„åå¤„ç†é…ç½®ã€‚ç”¨äºå¯¹åŸå§‹æ¨¡å‹è¾“å‡ºè¿›è¡Œæ ¼å¼åŒ–ã€æ¸…ç†æˆ–è½¬æ¢ï¼Œä»¥æ»¡è¶³ç‰¹å®šè¯„ä¼°ä»»åŠ¡çš„è¦æ±‚ |

**æ³¨æ„äº‹é¡¹ï¼š**
- `request_rate` å—ç¡¬ä»¶æ€§èƒ½å½±å“ï¼Œå¯é€šè¿‡å¢åŠ   ğŸ“š [WORKERS_NUM](./cli_args.md#é…ç½®å¸¸é‡æ–‡ä»¶å‚æ•°) æé«˜å¹¶å‘èƒ½åŠ›ã€‚
- `request_rate` åŠŸèƒ½å¯èƒ½è¢«`traffic_cfg`é¡¹è¦†ç›–ï¼Œå…·ä½“åŸå› è¯·å‚è€ƒ ğŸ”— [è¯·æ±‚é€Ÿç‡(RPS)åˆ†å¸ƒæ§åˆ¶åŠå¯è§†åŒ–è¯´æ˜ä¸­çš„å‚æ•°è§£è¯»ç« èŠ‚](../../advanced_tutorials/rps_distribution.md#å‚æ•°è§£è¯»)ã€‚
- `batch_size` è®¾ç½®è¿‡å¤§å¯èƒ½å¯¼è‡´ CPU å ç”¨è¿‡é«˜ï¼Œè¯·æ ¹æ®ç¡¬ä»¶æ¡ä»¶åˆç†é…ç½®ã€‚
- æœåŠ¡åŒ–æ¨ç†è¯„æµ‹ API é»˜è®¤ä½¿ç”¨çš„æœåŠ¡åœ°å€ä¸º `localhost:8080`ã€‚å®é™…ä½¿ç”¨æ—¶éœ€æ ¹æ®å®é™…éƒ¨ç½²ä¿®æ”¹ä¸ºæœåŠ¡åŒ–åç«¯çš„ IP å’Œç«¯å£ã€‚

## æœ¬åœ°æ¨¡å‹åç«¯
|æ¨¡å‹é…ç½®åç§°|ç®€ä»‹|ä½¿ç”¨å‰æ|æ”¯æŒçš„promptæ ¼å¼(å­—ç¬¦ä¸²æ ¼å¼æˆ–å¯¹è¯æ ¼å¼)|å¯¹åº”æºç é…ç½®æ–‡ä»¶è·¯å¾„|
| --- | --- | --- | --- | --- |
|`hf_base_model`|HuggingFace Base æ¨¡å‹åç«¯|å·²å®‰è£…è¯„æµ‹å·¥å…·åŸºç¡€ä¾èµ–ï¼Œéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š HuggingFace æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆå½“å‰ä¸æ”¯æŒè‡ªåŠ¨ä¸‹è½½ï¼‰|å­—ç¬¦ä¸²æ ¼å¼|[hf_base_model](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/hf_models/hf_base_model.py)|
|`hf_chat_model`|	HuggingFace Chat æ¨¡å‹åç«¯|å·²å®‰è£…è¯„æµ‹å·¥å…·åŸºç¡€ä¾èµ–ï¼Œéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š HuggingFace æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆå½“å‰ä¸æ”¯æŒè‡ªåŠ¨ä¸‹è½½ï¼‰|å¯¹è¯æ ¼å¼|[hf_chat_model](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/hf_models/hf_chat_model.py)|
|`hf_qwenvl_model`|	HuggingFace Chat QwenVLæ¨¡å‹åç«¯|å·²å®‰è£…è¯„æµ‹å·¥å…·åŸºç¡€ä¾èµ–ï¼Œéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š HuggingFace æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆå½“å‰ä¸æ”¯æŒè‡ªåŠ¨ä¸‹è½½ï¼‰|å¯¹è¯æ ¼å¼|[hf_qwenvl_model](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/hf_models/hf_qwenvl_model.py)|
|`vllm_offline_vl_model`|	vllm Chat QwenVLç¦»çº¿æ¨ç†æ¨¡å‹åç«¯|å·²å®‰è£…è¯„æµ‹å·¥å…·åŸºç¡€ä¾èµ–ï¼Œéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šæ¨¡å‹æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆå½“å‰ä¸æ”¯æŒè‡ªåŠ¨ä¸‹è½½ï¼‰|å¯¹è¯æ ¼å¼|[vllm_offline_vl_model](https://github.com/AISBench/benchmark/tree/master/ais_bench/benchmark/configs/models/vllm_offline_models/vllm_offline_vl_model.py)|

### æœ¬åœ°huggingfaceæ¨¡å‹åç«¯é…ç½®å‚æ•°è¯´æ˜
æœ¬åœ°huggingfaceæ¨¡å‹åç«¯é…ç½®æ–‡ä»¶é‡‡ç”¨Pythonè¯­æ³•æ ¼å¼é…ç½®ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š
```python
from ais_bench.benchmark.models import HuggingFacewithChatTemplate

models = [
    dict(
        attr="local",                       # åç«¯ç±»å‹æ ‡è¯†
        type=HuggingFacewithChatTemplate,   # æ¨¡å‹ç±»å‹
        abbr='hf-chat-model',               # å”¯ä¸€æ ‡è¯†
        path='THUDM/chatglm-6b',            # æ¨¡å‹æƒé‡è·¯å¾„
        tokenizer_path='THUDM/chatglm-6b',  # Tokenizer è·¯å¾„
        model_kwargs=dict(                  # æ¨¡å‹åŠ è½½å‚æ•°
            device_map="auto",
            trust_remote_code=True
        ),
        max_out_len=512,                    # æœ€å¤§è¾“å‡ºé•¿åº¦
        batch_size=1,                       # è¯·æ±‚å¹¶å‘æ•°
        generation_kwargs=dict(             # ç”Ÿæˆå‚æ•°
            temperature=0.5,
            top_k=10,
            top_p=0.95,
            seed=None,
            repetition_penalty=1.03,
        )
    )
]
```

æœ¬åœ°huggingfaceæ¨¡å‹æ¨ç†åç«¯å¯é…ç½®å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š
| å‚æ•°åç§° | å‚æ•°ç±»å‹ | è¯´æ˜ä¸é…ç½® |
|----------|-----------|-------------|
| `attr` | String | åç«¯ç±»å‹æ ‡è¯†ï¼Œå›ºå®šä¸º `local`ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰æˆ– `service`ï¼ˆæœåŠ¡åŒ–æ¨ç†ï¼‰ |
| `type` | Python Class | æ¨¡å‹ç±»åç§°ï¼Œç”±ç³»ç»Ÿè‡ªåŠ¨å…³è”ï¼Œç”¨æˆ·æ— éœ€æ‰‹åŠ¨é…ç½® |
| `abbr` | String | æœ¬åœ°ä»»åŠ¡çš„å”¯ä¸€æ ‡è¯†ï¼Œç”¨äºåŒºåˆ†å¤šä»»åŠ¡ã€‚å»ºè®®ä½¿ç”¨è‹±æ–‡ä¸çŸ­æ¨ªçº¿ç»„åˆï¼Œå¦‚ï¼š`hf-chat-model` |
| `path` | String | æ¨¡å‹æƒé‡è·¯å¾„ï¼Œéœ€ä¸ºæœ¬åœ°å¯è®¿é—®è·¯å¾„ã€‚ä½¿ç”¨ `AutoModel.from_pretrained(path)` åŠ è½½ |
| `tokenizer_path` | String | Tokenizer è·¯å¾„ï¼Œé€šå¸¸ä¸æ¨¡å‹è·¯å¾„ä¸€è‡´ã€‚ä½¿ç”¨ `AutoTokenizer.from_pretrained(tokenizer_path)` åŠ è½½ |
| `tokenizer_kwargs` | Dict | Tokenizer åŠ è½½å‚æ•°ï¼Œå‚è€ƒ ğŸ”— [PreTrainedTokenizerBase æ–‡æ¡£](https://huggingface.co/docs/transformers/v4.50.0/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase) |
| `model_kwargs` | Dict | æ¨¡å‹åŠ è½½å‚æ•°ï¼Œå‚è€ƒ ğŸ”— [AutoModel é…ç½®](https://huggingface.co/docs/transformers/v4.50.0/en/model_doc/auto#transformers.AutoConfig.from_pretrained) |
| `generation_kwargs` | Dict | æ¨ç†ç”Ÿæˆå‚æ•°ï¼Œå‚è€ƒ ğŸ”— [Text Generation æ–‡æ¡£](https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/text_generation) |
| `run_cfg` | Dict | è¿è¡Œé…ç½®ï¼ŒåŒ…å« `num_gpus`ï¼ˆä½¿ç”¨çš„ GPU æ•°é‡ï¼‰ä¸ `num_procs`ï¼ˆä½¿ç”¨çš„æœºå™¨è¿›ç¨‹æ•°ï¼‰ |
| `max_out_len` | Int | æ¨ç†ç”Ÿæˆçš„æœ€å¤§è¾“å‡º Token æ•°é‡ï¼Œåˆæ³•èŒƒå›´ï¼š(0, 131072] |
| `batch_size` | Int | æ¨ç†è¯·æ±‚çš„æ‰¹å¤„ç†å¤§å°ï¼Œåˆæ³•èŒƒå›´ï¼š(0, 64000] |
| `max_seq_len` | Int | æœ€å¤§è¾“å…¥åºåˆ—é•¿åº¦ï¼Œåˆæ³•èŒƒå›´ï¼š(0, 131072] |
| `batch_padding` | Bool | æ˜¯å¦å¯ç”¨æ‰¹é‡ paddingã€‚è®¾ç½®ä¸º `True` æˆ– `False` |

### æœ¬åœ°vllmç¦»çº¿æ¨ç†æ¨¡å‹åç«¯é…ç½®å‚æ•°è¯´æ˜
æœ¬åœ°vllmç¦»çº¿æ¨ç†æ¨¡å‹åç«¯é…ç½®æ–‡ä»¶é‡‡ç”¨Pythonè¯­æ³•æ ¼å¼é…ç½®ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š
```python
from ais_bench.benchmark.models import VLLMOfflineVLModel

models = [
    dict(
        attr="local",                    # åç«¯ç±»å‹æ ‡è¯†
        type=VLLMOfflineVLModel,         # æ¨¡å‹ç±»å‹
        abbr='vllm-offline-vl-model',    # å”¯ä¸€æ ‡è¯†
        path = "",                       # æ¨¡å‹æƒé‡è·¯å¾„
        model_kwargs=dict(               # æ¨¡å‹åˆå§‹åŒ–å‚æ•°, å¯å‚è€ƒ https://docs.vllm.com.cn/en/latest/serving/engine_args.html#
            max_num_seqs=5,
            max_model_len=32768,
            limit_mm_per_prompt={"image": 24},
            tensor_parallel_size=1,
            gpu_memory_utilization=0.9,
        ),
        sample_kwargs=dict(              # æ¨¡å‹æ¨ç†é‡‡æ ·å‚æ•°, å¯å‚è€ƒ https://docs.vllm.ai/en/v0.6.5/dev/sampling_params.html
            temperature=0.0,
            stop_token_ids=None
        ),
        vision_kwargs=dict(              # å¤šæ¨¡æ€è¾“å…¥å‚æ•°ï¼Œå¯å‚è€ƒ https://docs.vllm.ai/en/v0.7.3/getting_started/examples/vision_language.html
            min_pixels=1280 * 28 * 28,
            max_pixels=16384 * 28 * 28,
        ),
        max_out_len=512,                 # æœ€å¤§è¾“å‡ºé•¿åº¦
        batch_size=1,                    # è¯·æ±‚å¹¶å‘æ•°
    )
]
```

æœ¬åœ°vllmç¦»çº¿æ¨ç†æ¨¡å‹åç«¯å¯é…ç½®å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š
| å‚æ•°åç§° | å‚æ•°ç±»å‹ | è¯´æ˜ä¸é…ç½® |
|----------|-----------|-------------|
| `attr` | String | åç«¯ç±»å‹æ ‡è¯†ï¼Œå›ºå®šä¸º `local`ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰æˆ– `service`ï¼ˆæœåŠ¡åŒ–æ¨ç†ï¼‰ |
| `type` | Python Class | æ¨¡å‹ç±»åç§°ï¼Œç”±ç³»ç»Ÿè‡ªåŠ¨å…³è”ï¼Œç”¨æˆ·æ— éœ€æ‰‹åŠ¨é…ç½® |
| `abbr` | String | æœ¬åœ°ä»»åŠ¡çš„å”¯ä¸€æ ‡è¯†ï¼Œç”¨äºåŒºåˆ†å¤šä»»åŠ¡ã€‚å»ºè®®ä½¿ç”¨è‹±æ–‡ä¸çŸ­æ¨ªçº¿ç»„åˆï¼Œå¦‚ï¼š`vllm-offline-vl-model` |
| `path` | String | æ¨¡å‹æƒé‡è·¯å¾„ï¼Œéœ€ä¸ºæœ¬åœ°å¯è®¿é—®è·¯å¾„ã€‚ä½¿ç”¨ `vllm.LLM(model=path)` åŠ è½½ |
| `model_kwargs` | Dict | æ¨¡å‹åŠ è½½å‚æ•°ï¼Œå‚è€ƒ ğŸ”— [LLM æ¨¡å‹é…ç½®](https://docs.vllm.com.cn/en/latest/serving/engine_args.html#) |
| `sample_kwargs` | Dict | æ¨¡å‹æ¨ç†é‡‡æ ·å‚æ•°ï¼Œå‚è€ƒ ğŸ”— [sample parameteré…ç½®](https://docs.vllm.ai/en/v0.6.5/dev/sampling_params.html) |
| `vision_kwargs` | Dict | å¤šæ¨¡æ€è¾“å…¥å‚æ•°ï¼Œå‚è€ƒ ğŸ”— [å¤šæ¨¡æ€æ¨ç†ä¸¾ä¾‹](https://docs.vllm.ai/en/v0.7.3/getting_started/examples/vision_language.html) |
| `max_out_len` | Int | æ¨ç†ç”Ÿæˆçš„æœ€å¤§è¾“å‡º Token æ•°é‡ï¼Œåˆæ³•èŒƒå›´ï¼š(0, 131072] |
| `batch_size` | Int | æ¨ç†è¯·æ±‚çš„æ‰¹å¤„ç†å¤§å°ï¼Œåˆæ³•èŒƒå›´ï¼š(0, 64000] |